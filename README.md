
# Chat With AI Agent

## ğŸš€ Overview

This project is a **real-time AI chat application** that uses **Vue 3** for the frontend and **Django + Django Channels** for the backend, integrated with a **LLaMA-based multi-agent AI model** (Producer & Reviewer) for enhanced response quality.

## ğŸ“‚ Directory Structure

```
nikhilagarwal204-chatwithagent/
â”œâ”€â”€ client/               # Frontend (Vue 3 + Vite)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatWidget.vue
â”‚   â”‚   â”‚   â””â”€â”€ FileMessage.vue
â”‚   â”‚   â”œâ”€â”€ utils/websocket.js
â”‚   â”‚   â”œâ”€â”€ App.vue
â”‚   â”‚   â”œâ”€â”€ main.js
â”‚   â”‚   â”œâ”€â”€ assets/styles.css
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”œâ”€â”€ server/               # Backend (Django + ASGI WebSockets)
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â”œâ”€â”€ consumers.py   # WebSocket Handling
â”‚   â”‚   â”œâ”€â”€ models.py      # Chat Models
â”‚   â”‚   â”œâ”€â”€ agents/        # AI Agents
â”‚   â”‚   â”‚   â”œâ”€â”€ producer.py
â”‚   â”‚   â”‚   â”œâ”€â”€ reviewer.py
â”‚   â”‚   â”œâ”€â”€ routing.py
â”‚   â”‚   â”œâ”€â”€ serializers.py
â”‚   â”‚   â”œâ”€â”€ views.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â”œâ”€â”€ asgi.py        # Daphne ASGI Server
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md

```

## ğŸ¯ Features

âœ… **Real-time Chat** using WebSockets (Django Channels + ASGI + Daphne) âœ… **Multi-Agent AI Model** (Producer & Reviewer) for high-quality responses âœ… **Markdown Support** for AI-generated responses âœ… **File Uploads** (PDFs for AI context) âœ… **User Feedback** mechanism for model improvement âœ… **Dockerized Backend** for easy deployment

## ğŸ¤– AI Agent Workflow
```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant Backend
    participant Producer
    participant Reviewer
    
    User->>Frontend: Send message
    Frontend->>Backend: WebSocket message
    Backend->>Producer: Generate initial response
    Producer->>Reviewer: Submit draft
    Reviewer->>Producer: Feedback
    loop Refinement
        Producer->>Reviewer: Revised response
        Reviewer-->>Backend: Approval check
    end
    Backend->>Frontend: Final response
```
## âš™ï¸ Installation & Setup

### **1ï¸âƒ£ Backend Setup Locally**

#### **Install Dependencies**

```sh
cd server
python -m venv venv
source venv/bin/activate  # On Windows use `venv\Scripts\activate`
pip install -r requirements.txt

```

#### **Run Migrations**

```sh
python manage.py migrate

```
#### **Ollama Install**

```sh
ollama run llama3.2

```

#### **Run WebSocket Server**

```sh
daphne config.asgi:application --port 8000 --bind 0.0.0.0

```
## ğŸ³ or Docker Setup

```sh
docker-compose up --build

```

## ğŸ“Œ API Endpoints

| Endpoint         | Method    | Description              |
|-----------------|----------|--------------------------|
| `/ws/chat/`     | WebSocket | Chat communication      |
| `/api/upload/`  | POST      | Upload PDF documents    |
| `/api/feedback/` | POST      | Submit user feedback   |

### **2ï¸âƒ£ Frontend Setup**

```sh
cd client
npm install
npm run dev

```

## ğŸš€ Deployment Guide

-   **Backend:** Deploy Django with Daphne & Nginx
-   **Frontend:** Deploy Vue 3 on Vercel/Netlify
-   **Database:** Use PostgreSQL in production

## ğŸ“œ License

MIT License Â© 2024 Nikhil Agarwal
